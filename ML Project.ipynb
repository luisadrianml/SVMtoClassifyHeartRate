{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import time\n",
    "from sklearn import metrics\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "epsilon = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('SPECTF_test.txt', header= None)\n",
    "test = pd.read_csv('SPECTF_train.txt', header= None)\n",
    "train = np.array(train)\n",
    "test = np.array(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "True in np.isnan(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "True in np.isnan(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Lenght::  187\n",
      "Test Lenght::  80\n",
      "Train Shape::  (187, 45)\n",
      "Test Shape::  (80, 45)\n"
     ]
    }
   ],
   "source": [
    "print (\"Train Lenght:: \", len(train))\n",
    "print (\"Test Lenght:: \", len(test))\n",
    "\n",
    "print (\"Train Shape:: \", train.shape)\n",
    "print (\"Test Shape:: \", test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot of Class Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    172\n",
      "0     15\n",
      "Name: 0, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22fc6ec2be0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_plot = pd.DataFrame(train)\n",
    "print(train_plot[0].value_counts())\n",
    "train_plot[0].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    40\n",
      "0    40\n",
      "Name: 0, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22fc6f1ff98>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_plot = pd.DataFrame(test)\n",
    "print(test_plot[0].value_counts())\n",
    "test_plot[0].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separating train and test set for class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trainOriginal = train[:,1:]\n",
    "y_trainOriginal = train[:,0]\n",
    "\n",
    "x_testOriginal = test[:,1:]\n",
    "y_testOriginal = test[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merged train and test (70/30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = np.concatenate((train, test), axis = 0)\n",
    "x_trainMerged, x_testMerged, y_trainMerged, y_testMerged = train_test_split(merged[:,1:], merged[:,0], test_size=0.2996, random_state = random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    149\n",
      "0     38\n",
      "Name: 0, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22fc6f52828>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_trainMergedPlot = pd.DataFrame(y_trainMerged)\n",
    "print(y_trainMergedPlot[0].value_counts())\n",
    "y_trainMergedPlot[0].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    63\n",
      "0    17\n",
      "Name: 0, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22fc6fe74e0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_testMergedPlot = pd.DataFrame(y_testMerged)\n",
    "print(y_testMergedPlot[0].value_counts())\n",
    "y_testMergedPlot[0].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(x,w):\n",
    "    x=np.array(x)\n",
    "    w=np.array(w)\n",
    "    \n",
    "    x = np.column_stack((x, np.ones(len(x))))\n",
    "    \n",
    "    y = []\n",
    "    for i in range(len(x)):\n",
    "        classify = np.dot(w,x[i]) \n",
    "        #print(classify)\n",
    "        if  classify >= 1:\n",
    "            y.append(1)\n",
    "        elif classify <= -1:\n",
    "            y.append(0)\n",
    "    return(y)\n",
    "\n",
    "## Special case for classifier with wTx+b>=0\n",
    "def classifySpecialCase(x,w):\n",
    "    x=np.array(x)\n",
    "    w=np.array(w)\n",
    "    \n",
    "    x = np.column_stack((x, np.ones(len(x))))\n",
    "    \n",
    "    y = []\n",
    "    for i in range(len(x)):\n",
    "        classify = np.dot(w,x[i]) \n",
    "        #print(classify)\n",
    "        if  classify >= 0:\n",
    "            y.append(1)\n",
    "        elif classify < 0:\n",
    "            y.append(0)\n",
    "    return(y)\n",
    "    \n",
    "    \n",
    "def svmTest(x,w,y):\n",
    "    correctCount = 0\n",
    "    predictedValues = classify(x,w)\n",
    "    #print(predictedValues)\n",
    "    for ipoint in range(len(x)):\n",
    "        #print(ipoint, y[ipoint], predictedValues[ipoint])\n",
    "        if (predictedValues[ipoint]==y[ipoint]):\n",
    "            correctCount += 1\n",
    "            \n",
    "    return(correctCount/len(x))\n",
    "\n",
    "## Special case for test classifier with wTx+b>=0\n",
    "def svmTestSpecialCase(x,w,y):\n",
    "    correctCount = 0\n",
    "    predictedValues = classifySpecialCase(x,w)\n",
    "    #print(predictedValues)\n",
    "    for ipoint in range(len(x)):\n",
    "        #print(ipoint, y[ipoint], predictedValues[ipoint])\n",
    "        if (predictedValues[ipoint]==y[ipoint]):\n",
    "            correctCount += 1\n",
    "            \n",
    "    return(correctCount/len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to Update Gammas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateGamma(x,y,w,gamma,epsilon):\n",
    "    valuePositive = 0\n",
    "    valueNegative = 0\n",
    "    for idata in range(len(x)):   \n",
    "        if(y[idata]==1): ## class 1 is positive class\n",
    "            valuePositive += 1 - np.dot(w,x[idata])\n",
    "        else:\n",
    "            valueNegative += np.dot(w,x[idata]) + 1\n",
    "    gamma = gamma - epsilon*(valuePositive + valueNegative)\n",
    "    \n",
    "    return(gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateMultipleGammas(x,y,w,gammas,epsilon):\n",
    "    gammas=np.array(gammas)\n",
    "    valuePositive = 0\n",
    "    valueNegative = 0\n",
    "    for idata in range(len(x)):   \n",
    "        if(y[idata]==1): ## class 1 is positive class\n",
    "            gammas[idata] = gammas[idata] - epsilon*((1-(np.dot(w,x[idata])))+1)\n",
    "        else:\n",
    "            gammas[idata] = gammas[idata] - epsilon*((np.dot(w,x[idata])+1)+1)\n",
    "    return(gammas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine - Traditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learnWeights(w0, gamma, x, y, epsilon):\n",
    "    w0=np.array(w0).astype(float)\n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "    \n",
    "    x = np.column_stack((x, np.ones(len(x))))\n",
    "        \n",
    "    gamma = gamma\n",
    "    epsilon = epsilon\n",
    "    \n",
    "    for i in range(len(w0)):\n",
    "        sumPositiveClass = 0\n",
    "        sumNegativeClass = 0\n",
    "        for d in range(len(x)):\n",
    "            if(y[d]==1):\n",
    "                sumPositiveClass += x[d][i]\n",
    "            else:\n",
    "                sumNegativeClass += x[d][i]\n",
    "                        \n",
    "        w0[i] = w0[i] - epsilon*((2*w0[i])-(gamma*sumPositiveClass)+(gamma*sumNegativeClass))\n",
    "        \n",
    "    gamma = updateGamma(x,y,w0,gamma,epsilon)\n",
    "        \n",
    "    return(gamma,w0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learnWeightsGammas(w0, gammas, x, y, epsilon):\n",
    "    w0=np.array(w0).astype(float)\n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "    gammas = np.array(gammas)\n",
    "    \n",
    "    x = np.column_stack((x, np.ones(len(x))))\n",
    "        \n",
    "    epsilon = epsilon\n",
    "    \n",
    "    for i in range(len(w0)):\n",
    "        sumPositiveClass = 0\n",
    "        sumNegativeClass = 0\n",
    "        for d in range(len(x)):\n",
    "            if(y[d]==1):\n",
    "                sumPositiveClass += x[d][i]*gammas[d]\n",
    "            else:\n",
    "                sumNegativeClass += x[d][i]*gammas[d]\n",
    "        \n",
    "        w0[i] = w0[i] - epsilon*(2*w0[i]-sumPositiveClass+sumNegativeClass)\n",
    "        \n",
    "    gammas = updateMultipleGammas(x,y,w0,gammas,epsilon)\n",
    "\n",
    "    return(gammas,w0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing linearly separation of my SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('test_linearlyseparable.csv', header= None)\n",
    "dataset = np.array(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trainTESTLINEAR, x_testTESTLINEAR, y_trainTESTLINEAR, y_testTESTLINEAR = train_test_split(dataset[:,1:], dataset[:,0], test_size=0.2996, random_state = random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g,w = learnWeights([0 for i in range(x_trainTESTLINEAR.shape[1]+1)], 0.01, x_trainTESTLINEAR, y_trainTESTLINEAR, epsilon)\n",
    "svmTest(x_testTESTLINEAR, w, y_testTESTLINEAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10195 0.0994  0.10691 0.10634 0.09862 0.0957  0.10807 0.10634 0.09759\n",
      " 0.09544 0.11048 0.10909 0.10356 0.10289 0.09281 0.09031 0.10391 0.10308\n",
      " 0.10292 0.10089 0.11553 0.11235 0.10401 0.10235 0.08676 0.08233 0.09936\n",
      " 0.0967  0.09314 0.09053 0.1103  0.10837 0.09416 0.0935  0.09856 0.09537\n",
      " 0.1017  0.0996  0.09897 0.09513 0.09224 0.08786 0.07723 0.07303 0.00157]\n",
      "43.075422149999994\n"
     ]
    }
   ],
   "source": [
    "g,w = learnWeights([0 for i in range(x_trainOriginal.shape[1]+1)], 0.01, x_trainOriginal, y_trainOriginal, epsilon)\n",
    "print(w) ## Updated Weights\n",
    "print(g) ## Updated Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svmTest(x_testOriginal, w, y_testOriginal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10195 0.0994  0.10691 0.10634 0.09862 0.0957  0.10807 0.10634 0.09759\n",
      " 0.09544 0.11048 0.10909 0.10356 0.10289 0.09281 0.09031 0.10391 0.10308\n",
      " 0.10292 0.10089 0.11553 0.11235 0.10401 0.10235 0.08676 0.08233 0.09936\n",
      " 0.0967  0.09314 0.09053 0.1103  0.10837 0.09416 0.0935  0.09856 0.09537\n",
      " 0.1017  0.0996  0.09897 0.09513 0.09224 0.08786 0.07723 0.07303 0.00157]\n",
      "[ 0.30906585  0.30229465  0.30236977  0.3026732   0.30102278  0.31206866\n",
      "  0.29431823  0.28025521  0.25826355  0.29540726  0.27817474  0.2674045\n",
      "  0.30044972  0.24417466  0.25499482  0.23392595  0.30800674  0.29357504\n",
      "  0.27138798  0.28721969  0.28939758  0.25624032  0.26460383  0.29469242\n",
      "  0.29042066  0.28884058  0.28889463  0.29854916  0.30332156  0.30678864\n",
      "  0.31337278  0.31138839  0.24208023  0.28166974  0.30910932  0.30561893\n",
      "  0.30383415  0.24602934  0.22742027  0.25887523  0.23785346  0.3110306\n",
      "  0.28569942  0.21948274  0.28829426  0.29457867  0.27516367  0.27769806\n",
      "  0.31106797  0.29647844  0.29232183  0.24264968  0.27878345  0.29523824\n",
      "  0.3123258   0.30099727  0.22244429  0.27584077  0.28972787  0.30344793\n",
      "  0.30079904  0.27629067  0.30454404  0.2942192   0.31143324  0.21080277\n",
      "  0.30531756  0.28864184  0.2971437   0.25265023  0.29007642  0.29642621\n",
      "  0.29424136  0.20986088  0.31131848  0.29455308  0.28555068  0.30009543\n",
      "  0.30801388  0.2757909   0.27075153  0.28889416  0.26103438  0.30364387\n",
      "  0.27425516  0.20793773  0.29005338  0.2406997   0.29929229  0.28374794\n",
      "  0.31028039  0.22144333  0.30075461  0.29006106  0.30846284  0.30143287\n",
      "  0.3066243   0.29514767  0.30019217  0.29336166  0.29872975  0.31552449\n",
      "  0.29285523  0.29233444  0.29342772  0.30836308  0.30745021  0.30202509\n",
      "  0.30746663  0.31191621  0.31114828  0.28521243  0.27103351  0.29405479\n",
      "  0.30490545  0.30685298  0.30513364  0.31023441  0.29531977  0.29249127\n",
      "  0.31078209  0.29590933  0.30624698  0.31208651  0.29834335  0.30051318\n",
      "  0.29397617  0.31317097  0.31075278  0.29694876  0.26180777  0.28721086\n",
      "  0.30158824  0.25528715  0.30663829  0.2890921   0.23300964  0.28050764\n",
      "  0.29149652  0.22272573  0.28455425  0.23958232  0.29269927  0.29813738\n",
      "  0.28382858  0.30908458  0.26953581  0.27088612  0.26687261  0.31010984\n",
      "  0.30017778  0.29186066  0.30249472  0.29055733  0.30143638  0.30796227\n",
      "  0.30857913  0.19376495  0.21887583  0.27436778  0.28869828  0.28875721\n",
      "  0.289162    0.30149676  0.28109582  0.29486356  0.30605336  0.27736736\n",
      "  0.29909058  0.30488199  0.29385242  0.29198848 -0.29315251 -0.28250224\n",
      " -0.28534485 -0.28203515 -0.28018231 -0.29513058 -0.28971795 -0.2744004\n",
      " -0.28995703 -0.2874933  -0.28939041 -0.28796614 -0.29892073 -0.29033667\n",
      " -0.29046226]\n"
     ]
    }
   ],
   "source": [
    "g,w = learnWeightsGammas([0 for i in range(x_trainOriginal.shape[1]+1)], [0.01 for i in range(x_trainOriginal.shape[0])], x_trainOriginal, y_trainOriginal, epsilon)\n",
    "print(w) ## Weights\n",
    "print(g) ## Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svmTest(x_testOriginal, w, y_testOriginal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07256 0.07    0.07469 0.07312 0.06968 0.06664 0.07635 0.07397 0.06968\n",
      " 0.06717 0.07757 0.07607 0.07221 0.07126 0.06451 0.06177 0.07383 0.07271\n",
      " 0.07172 0.06931 0.08065 0.07761 0.0718  0.07    0.05818 0.05424 0.06897\n",
      " 0.06686 0.06308 0.06005 0.07671 0.07523 0.06548 0.06568 0.06846 0.06551\n",
      " 0.07165 0.0698  0.06796 0.06457 0.06142 0.05829 0.05138 0.04838 0.00111]\n",
      "20.583399870000004\n"
     ]
    }
   ],
   "source": [
    "g,w = learnWeights([0 for i in range(x_trainMerged.shape[1]+1)], 0.01, x_trainMerged, y_trainMerged, epsilon)\n",
    "print(w) ## Weights\n",
    "print(g) ## Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7875"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svmTest(x_testMerged, w, y_testMerged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07256 0.07    0.07469 0.07312 0.06968 0.06664 0.07635 0.07397 0.06968\n",
      " 0.06717 0.07757 0.07607 0.07221 0.07126 0.06451 0.06177 0.07383 0.07271\n",
      " 0.07172 0.06931 0.08065 0.07761 0.0718  0.07    0.05818 0.05424 0.06897\n",
      " 0.06686 0.06308 0.06005 0.07671 0.07523 0.06548 0.06568 0.06846 0.06551\n",
      " 0.07165 0.0698  0.06796 0.06457 0.06142 0.05829 0.05138 0.04838 0.00111]\n",
      "[ 0.21359116  0.21603722 -0.19244988  0.19961926  0.19970298  0.18962452\n",
      "  0.20627361  0.20699274 -0.19758692 -0.19340856  0.17813774  0.21226631\n",
      "  0.20080824  0.21512846  0.19704656  0.19997681  0.21073761  0.19519203\n",
      "  0.21081343  0.21826762  0.21187953  0.21514115  0.21646692 -0.19804517\n",
      "  0.20739389  0.19026811  0.21876679  0.15720352  0.1900249  -0.19771551\n",
      " -0.19748101  0.14881727  0.21792032  0.14726525 -0.20091006  0.20765697\n",
      "  0.21823029  0.21089433  0.21428705  0.21258999  0.20064607  0.1547945\n",
      "  0.2154857  -0.20076516  0.18636511  0.20547356  0.20390812 -0.1897464\n",
      "  0.16833551  0.17081098  0.2116913  -0.2040622  -0.19278822  0.21819021\n",
      "  0.20705333  0.20619443  0.1638907   0.20291593 -0.20513839  0.21595358\n",
      "  0.21656058  0.21490361  0.2094487   0.20318924  0.20609698  0.2108158\n",
      "  0.21318461  0.19402056 -0.19604525 -0.19644581  0.18830635 -0.19718288\n",
      " -0.20173513  0.20942633 -0.20008801  0.21110716  0.2148156   0.17097997\n",
      "  0.2031316   0.20761736  0.20474354  0.21363924  0.20307342  0.21781028\n",
      " -0.20017275  0.15133511  0.20368589  0.21090574  0.21840623  0.20258343\n",
      " -0.19787019  0.21622653  0.16791257  0.21873812  0.20376275  0.20676761\n",
      "  0.21505676  0.20804908  0.20269211  0.18238909 -0.20240646  0.19532786\n",
      "  0.21620957  0.17167287  0.20269142  0.15534956  0.21666494  0.20681241\n",
      "  0.21231441  0.21634063  0.20736109  0.17966289 -0.19475458 -0.19323455\n",
      "  0.20558784  0.20810987  0.21154051  0.19058485  0.21672751 -0.19331616\n",
      "  0.19680395  0.2048941   0.21985949 -0.19249277  0.2182319   0.15663639\n",
      "  0.21306913 -0.20194504 -0.199836    0.19921861  0.181786    0.1722013\n",
      "  0.21298786 -0.19507035  0.20168318  0.20590811  0.21458903  0.20645838\n",
      " -0.20124835  0.21506512  0.20180523 -0.19978625  0.20667082  0.21888401\n",
      "  0.21184741  0.20501434 -0.20305158 -0.19477308 -0.19919037  0.20561295\n",
      "  0.17963614  0.20794499 -0.19956012  0.19911286  0.21370011  0.2034036\n",
      "  0.18164444  0.21814865  0.20992308 -0.19352442  0.18084319  0.1941405\n",
      "  0.19127903  0.20263471 -0.19734664  0.20506083  0.20281543  0.2084008\n",
      "  0.17368177  0.13732132 -0.20011661 -0.19804389  0.21210684  0.19600141\n",
      "  0.21745051  0.18413948  0.20472138  0.20602077  0.17003037  0.20747654\n",
      "  0.20750046 -0.19356167  0.20339999  0.2183059   0.20813186  0.2154905\n",
      "  0.2055297 ]\n"
     ]
    }
   ],
   "source": [
    "g,w = learnWeightsGammas([0 for i in range(x_trainMerged.shape[1]+1)], [0.01 for i in range(x_trainMerged.shape[0])], x_trainMerged, y_trainMerged, epsilon)\n",
    "print(w) ## Weights\n",
    "print(g) ## Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7875"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svmTest(x_testMerged, w, y_testMerged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine - Optimization (L1 regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign(wValue): \n",
    "    if(wValue>=0):\n",
    "        return(1)\n",
    "    else:\n",
    "        return(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learnWeightOptimization(w0, gamma, x, y, lamb, epsilon):\n",
    "    w0=np.array(w0).astype(float)\n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "    \n",
    "    x = np.column_stack((x, np.ones(len(x))))\n",
    "        \n",
    "    gamma = gamma\n",
    "    epsilon = 0.001\n",
    "    lam = lamb\n",
    "    \n",
    "    for i in range(len(w0)):\n",
    "        sumPositiveClass = 0\n",
    "        sumNegativeClass = 0\n",
    "        for d in range(len(x)):\n",
    "            if(y[d]==1):\n",
    "                sumPositiveClass += x[d][i]\n",
    "            else:\n",
    "                sumNegativeClass += x[d][i]\n",
    "        \n",
    "        w0[i] = w0[i] - epsilon*(2*w0[i]-gamma*sumPositiveClass+gamma*sumNegativeClass) + lam*sign(w0[i]) \n",
    "\n",
    "    gamma = updateGamma(x,y,w0,gamma,epsilon)\n",
    "        \n",
    "    return(gamma,w0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learnWeightOptimizationGammas(w0, gammas, x, y, lamb, epsilon):\n",
    "    w0=np.array(w0).astype(float)\n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "    gammas = np.array(gammas)\n",
    "\n",
    "    x = np.column_stack((x, np.ones(len(x))))\n",
    "        \n",
    "    epsilon = 0.001\n",
    "    lam = lamb\n",
    "    \n",
    "    for i in range(len(w0)):\n",
    "        sumPositiveClass = 0\n",
    "        sumNegativeClass = 0\n",
    "        for d in range(len(x)):\n",
    "            if(y[d]==1):\n",
    "                sumPositiveClass += x[d][i]*gammas[d]\n",
    "            else:\n",
    "                sumNegativeClass += x[d][i]*gammas[d]\n",
    "        \n",
    "        w0[i] = w0[i] - epsilon*(2*w0[i]-sumPositiveClass+sumNegativeClass) + lam*sign(w0[i]) \n",
    "\n",
    "    gammas = updateMultipleGammas(x,y,w0,gammas,epsilon)\n",
    "        \n",
    "    return(gammas,w0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11195 0.1094  0.11691 0.11634 0.10862 0.1057  0.11807 0.11634 0.10759\n",
      " 0.10544 0.12048 0.11909 0.11356 0.11289 0.10281 0.10031 0.11391 0.11308\n",
      " 0.11292 0.11089 0.12553 0.12235 0.11401 0.11235 0.09676 0.09233 0.10936\n",
      " 0.1067  0.10314 0.10053 0.1203  0.11837 0.10416 0.1035  0.10856 0.10537\n",
      " 0.1117  0.1096  0.10897 0.10513 0.10224 0.09786 0.08723 0.08303 0.01157]\n",
      "47.422372149999994\n"
     ]
    }
   ],
   "source": [
    "g,w = learnWeightOptimization([0 for i in range(x_trainOriginal.shape[1]+1)], 0.01, x_trainOriginal, y_trainOriginal, 0.01, epsilon)\n",
    "print(w) ## Updated Weights\n",
    "print(g) ## Updated Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svmTest(x_testOriginal, w, y_testOriginal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11195 0.1094  0.11691 0.11634 0.10862 0.1057  0.11807 0.11634 0.10759\n",
      " 0.10544 0.12048 0.11909 0.11356 0.11289 0.10281 0.10031 0.11391 0.11308\n",
      " 0.11292 0.11089 0.12553 0.12235 0.11401 0.11235 0.09676 0.09233 0.10936\n",
      " 0.1067  0.10314 0.10053 0.1203  0.11837 0.10416 0.1035  0.10856 0.10537\n",
      " 0.1117  0.1096  0.10897 0.10513 0.10224 0.09786 0.08723 0.08303 0.01157]\n",
      "[ 0.33936585  0.33182465  0.33182977  0.3323132   0.33045278  0.34266866\n",
      "  0.32298823  0.30760521  0.28329355  0.32415726  0.30527474  0.2931945\n",
      "  0.32971972  0.26772466  0.27943482  0.25648595  0.33817674  0.32234504\n",
      "  0.29772798  0.31534969  0.31744758  0.28075032  0.29005383  0.32346242\n",
      "  0.31870066  0.31681058  0.31702463  0.32774916  0.33307156  0.33681864\n",
      "  0.34408278  0.34190839  0.26518023  0.30917974  0.33934932  0.33558893\n",
      "  0.33351415  0.26955934  0.24937027  0.28379523  0.26081346  0.3414206\n",
      "  0.31350942  0.24025274  0.31631426  0.32331867  0.30206367  0.30455806\n",
      "  0.34147797  0.32538844  0.32102183  0.26609968  0.30571345  0.32393824\n",
      "  0.3429258   0.33036727  0.24364429  0.30239077  0.31797787  0.33306793\n",
      "  0.33015904  0.30344067  0.33432404  0.3227592   0.34187324  0.23092277\n",
      "  0.33502756  0.31674184  0.3262037   0.27692023  0.31835642  0.32534621\n",
      "  0.32304136  0.23009088  0.34172848  0.32323308  0.31316068  0.32934543\n",
      "  0.33811388  0.3023309   0.29681153  0.31714416  0.28630438  0.33328387\n",
      "  0.30093516  0.22774773  0.31824338  0.2636297   0.32858229  0.31149794\n",
      "  0.34054039  0.24241333  0.33001461  0.31822106  0.33867284  0.33076287\n",
      "  0.3365743   0.32388767  0.32941217  0.32189166  0.32797975  0.34644449\n",
      "  0.32148523  0.32062444  0.32208772  0.33848308  0.33762021  0.33159509\n",
      "  0.33759663  0.34252621  0.34155828  0.31292243  0.29750351  0.32273479\n",
      "  0.33484545  0.33693298  0.33504364  0.34057441  0.32417977  0.32117127\n",
      "  0.34131209  0.32493933  0.33620698  0.34269651  0.32747335  0.33000318\n",
      "  0.32273617  0.34380097  0.34121278  0.32601876  0.28717777  0.31515086\n",
      "  0.33113824  0.28007715  0.33664829  0.3172221   0.25560964  0.30783764\n",
      "  0.31988652  0.24381573  0.31221425  0.26286232  0.32123927  0.32718738\n",
      "  0.31127858  0.33937458  0.29570581  0.29742612  0.29240261  0.34044984\n",
      "  0.32961778  0.32046066  0.33213472  0.31907733  0.33082638  0.33809227\n",
      "  0.33882913  0.21206495  0.23972583  0.30095778  0.31692828  0.31700721\n",
      "  0.317282    0.33095676  0.30830582  0.32363356  0.33601336  0.30410736\n",
      "  0.32844058  0.33480199  0.32259242  0.32052848 -0.32369251 -0.31195224\n",
      " -0.31500485 -0.31138515 -0.30935231 -0.32582058 -0.31974795 -0.3031004\n",
      " -0.32020703 -0.3174533  -0.31946041 -0.31789614 -0.33003073 -0.32061667\n",
      " -0.32061226]\n"
     ]
    }
   ],
   "source": [
    "g,w = learnWeightOptimizationGammas([0 for i in range(x_trainOriginal.shape[1]+1)], [0.01 for i in range(x_trainOriginal.shape[0])], x_trainOriginal, y_trainOriginal, 0.01, epsilon)\n",
    "print(w) ## Weights\n",
    "print(g) ## Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svmTest(x_testOriginal, w, y_testOriginal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08256 0.08    0.08469 0.08312 0.07968 0.07664 0.08635 0.08397 0.07968\n",
      " 0.07717 0.08757 0.08607 0.08221 0.08126 0.07451 0.07177 0.08383 0.08271\n",
      " 0.08172 0.07931 0.09065 0.08761 0.0818  0.08    0.06818 0.06424 0.07897\n",
      " 0.07686 0.07308 0.07005 0.08671 0.08523 0.07548 0.07568 0.07846 0.07551\n",
      " 0.08165 0.0798  0.07796 0.07457 0.07142 0.06829 0.06138 0.05838 0.01111]\n",
      "23.591289870000004\n"
     ]
    }
   ],
   "source": [
    "g,w = learnWeightOptimization([0 for i in range(x_trainMerged.shape[1]+1)], 0.01, x_trainMerged, y_trainMerged, 0.01, epsilon)\n",
    "print(w) ## Weights\n",
    "print(g) ## Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7875"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svmTest(x_testMerged, w, y_testMerged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08256 0.08    0.08469 0.08312 0.07968 0.07664 0.08635 0.08397 0.07968\n",
      " 0.07717 0.08757 0.08607 0.08221 0.08126 0.07451 0.07177 0.08383 0.08271\n",
      " 0.08172 0.07931 0.09065 0.08761 0.0818  0.08    0.06818 0.06424 0.07897\n",
      " 0.07686 0.07308 0.07005 0.08671 0.08523 0.07548 0.07568 0.07846 0.07551\n",
      " 0.08165 0.0798  0.07796 0.07457 0.07142 0.06829 0.06138 0.05838 0.01111]\n",
      "[ 0.24353116  0.24613722 -0.22179988  0.22706926  0.22707298  0.21579452\n",
      "  0.23503361  0.23576274 -0.22765692 -0.22300856  0.20240774  0.24172631\n",
      "  0.22841824  0.24507846  0.22437656  0.22763681  0.24022761  0.22193203\n",
      "  0.24028343  0.24867762  0.24145953  0.24517115  0.24668692 -0.22832517\n",
      "  0.23610389  0.21673811  0.24936679  0.17840352  0.2165649  -0.22787551\n",
      " -0.22760101  0.16893727  0.24830032  0.16707525 -0.23143006  0.23665697\n",
      "  0.24875029  0.24016433  0.24425705  0.24233999  0.22845607  0.1756445\n",
      "  0.2456157  -0.23134516  0.21181511  0.23401356  0.23206812 -0.2188164\n",
      "  0.19161551  0.19426098  0.2410213  -0.2351722  -0.22223822  0.24858021\n",
      "  0.23594333  0.23493443  0.1864907   0.23104593 -0.23636839  0.24608358\n",
      "  0.24686058  0.24479361  0.2386987   0.23148924  0.23481698  0.2400358\n",
      "  0.24286461  0.22117056 -0.22600525 -0.22634581  0.21409635 -0.22733288\n",
      " -0.23245513  0.23862633 -0.23062801  0.24053716  0.2447756   0.19407997\n",
      "  0.2312516   0.23648736  0.23313354  0.24341924  0.23120342  0.24827028\n",
      " -0.23075275  0.17198511  0.23196589  0.24006574  0.24884623  0.23060343\n",
      " -0.22812019  0.24647653  0.19087257  0.24934812  0.23228275  0.23553761\n",
      "  0.24510676  0.23706908  0.23094211  0.20730909 -0.23322646  0.22218786\n",
      "  0.24641957  0.19547287  0.23094142  0.17611956  0.24695494  0.23570241\n",
      "  0.24195441  0.24646063  0.23606109  0.20445289 -0.22457458 -0.22282455\n",
      "  0.23387784  0.23701987  0.24100051  0.21664485  0.24696751 -0.22281616\n",
      "  0.22415395  0.2334341   0.25064949 -0.22168277  0.2486419   0.17760639\n",
      "  0.24270913 -0.23268504 -0.230236    0.22696861  0.206816    0.1957513\n",
      "  0.24260786 -0.22482035  0.22962318  0.23467811  0.24454903  0.23525838\n",
      " -0.23180835  0.24507512  0.22971523 -0.23017625  0.23521082  0.24948401\n",
      "  0.24141741  0.23371434 -0.23402158 -0.22443308 -0.22956037  0.23407295\n",
      "  0.20407614  0.23706499 -0.23003012  0.22632286  0.24362011  0.2316536\n",
      "  0.20638444  0.24855865  0.23921308 -0.22309442  0.20535319  0.2206905\n",
      "  0.21756903  0.23086471 -0.22734664  0.23371083  0.23081543  0.2374708\n",
      "  0.19721177  0.15562132 -0.23060661 -0.22821389  0.24163684  0.22293141\n",
      "  0.24779051  0.20950948  0.23332138  0.23455077  0.19296037  0.23610654\n",
      "  0.23653046 -0.22312167  0.23144999  0.2488559   0.23705186  0.2456605\n",
      "  0.2341597 ]\n"
     ]
    }
   ],
   "source": [
    "g,w = learnWeightOptimizationGammas([0 for i in range(x_trainMerged.shape[1]+1)], [0.01 for i in range(x_trainMerged.shape[0])], x_trainMerged, y_trainMerged, 0.01, epsilon)\n",
    "print(w) ## Weights\n",
    "print(g) ## Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7875"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svmTest(x_testMerged, w, y_testMerged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smartLoopTraditional(k, learningMethod, testMethod, xtrain, ytrain, xtest, ytest, epsilon, initialGamma, initialWeight):\n",
    "    loop = 0    \n",
    "    gCurrent,wCurrent=learningMethod(initialWeight, initialGamma, xtrain, ytrain, epsilon)\n",
    "    accuracy = testMethod(xtest, wCurrent, ytest)\n",
    "    finalW = wCurrent\n",
    "    finalG = gCurrent\n",
    "    finalA = accuracy\n",
    "\n",
    "    while (loop<k):\n",
    "        oldG = gCurrent\n",
    "        oldW = wCurrent\n",
    "        oldAccuracy = accuracy\n",
    "\n",
    "        gCurrent,wCurrent=learningMethod(oldW,oldG,xtrain,ytrain,epsilon)\n",
    "        \n",
    "        accuracy = testMethod(xtest, wCurrent, ytest)\n",
    "        \n",
    "        if(accuracy>oldAccuracy):\n",
    "            pass ## Keep improving till we can't\n",
    "        elif(accuracy==oldAccuracy):\n",
    "            finalW = oldW\n",
    "            finalG = oldG\n",
    "            finalA = oldAccuracy\n",
    "            break\n",
    "        else:\n",
    "            finalW = oldW\n",
    "            finalG = oldG\n",
    "            finalA = oldAccuracy\n",
    "            \n",
    "        loop+=1\n",
    "    return(finalW, finalG, loop, finalA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smartLoopOptimization(k, learningMethod, testMethod, xtrain, ytrain, xtest, ytest, epsilon, lamb, initialGamma, initialWeight):\n",
    "    loop = 0    \n",
    "    gCurrent,wCurrent=learningMethod(initialWeight, initialGamma, xtrain, ytrain,lamb, epsilon)\n",
    "    accuracy = testMethod(xtest, wCurrent, ytest)\n",
    "    finalW = wCurrent\n",
    "    finalG = gCurrent\n",
    "    finalA = accuracy\n",
    "\n",
    "    while (loop<k):\n",
    "        oldG = gCurrent\n",
    "        oldW = wCurrent\n",
    "        oldAccuracy = accuracy\n",
    "\n",
    "        gCurrent,wCurrent=learningMethod(oldW,oldG,xtrain,ytrain,lamb,epsilon)\n",
    "        \n",
    "        accuracy = testMethod(xtest, wCurrent, ytest)\n",
    "        \n",
    "        if(accuracy>oldAccuracy):\n",
    "            pass ## Keep improving till we can't\n",
    "        elif(accuracy==oldAccuracy):\n",
    "            finalW = oldW\n",
    "            finalG = oldG\n",
    "            finalA = oldAccuracy\n",
    "            break\n",
    "        else:\n",
    "            finalW = oldW\n",
    "            finalG = oldG\n",
    "            finalA = oldAccuracy\n",
    "            \n",
    "        loop+=1\n",
    "    return(finalW, finalG, loop, finalA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traditional: One Gamma - Original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.10195, 0.0994 , 0.10691, 0.10634, 0.09862, 0.0957 , 0.10807,\n",
       "        0.10634, 0.09759, 0.09544, 0.11048, 0.10909, 0.10356, 0.10289,\n",
       "        0.09281, 0.09031, 0.10391, 0.10308, 0.10292, 0.10089, 0.11553,\n",
       "        0.11235, 0.10401, 0.10235, 0.08676, 0.08233, 0.09936, 0.0967 ,\n",
       "        0.09314, 0.09053, 0.1103 , 0.10837, 0.09416, 0.0935 , 0.09856,\n",
       "        0.09537, 0.1017 , 0.0996 , 0.09897, 0.09513, 0.09224, 0.08786,\n",
       "        0.07723, 0.07303, 0.00157]), 43.075422149999994, 0, 0.5)"
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smartLoopTraditional(5, learnWeights, svmTest, x_trainOriginal, y_trainOriginal, x_testOriginal, y_testOriginal, epsilon, 0.01 ,[0 for i in range(x_trainOriginal.shape[1]+1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traditional: Multiple Gamma - Original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.10195, 0.0994 , 0.10691, 0.10634, 0.09862, 0.0957 , 0.10807,\n",
       "        0.10634, 0.09759, 0.09544, 0.11048, 0.10909, 0.10356, 0.10289,\n",
       "        0.09281, 0.09031, 0.10391, 0.10308, 0.10292, 0.10089, 0.11553,\n",
       "        0.11235, 0.10401, 0.10235, 0.08676, 0.08233, 0.09936, 0.0967 ,\n",
       "        0.09314, 0.09053, 0.1103 , 0.10837, 0.09416, 0.0935 , 0.09856,\n",
       "        0.09537, 0.1017 , 0.0996 , 0.09897, 0.09513, 0.09224, 0.08786,\n",
       "        0.07723, 0.07303, 0.00157]),\n",
       " array([ 0.30806585,  0.30129465,  0.30136977,  0.3016732 ,  0.30002278,\n",
       "         0.31106866,  0.29331823,  0.27925521,  0.25726355,  0.29440726,\n",
       "         0.27717474,  0.2664045 ,  0.29944972,  0.24317466,  0.25399482,\n",
       "         0.23292595,  0.30700674,  0.29257504,  0.27038798,  0.28621969,\n",
       "         0.28839758,  0.25524032,  0.26360383,  0.29369242,  0.28942066,\n",
       "         0.28784058,  0.28789463,  0.29754916,  0.30232156,  0.30578864,\n",
       "         0.31237278,  0.31038839,  0.24108023,  0.28066974,  0.30810932,\n",
       "         0.30461893,  0.30283415,  0.24502934,  0.22642027,  0.25787523,\n",
       "         0.23685346,  0.3100306 ,  0.28469942,  0.21848274,  0.28729426,\n",
       "         0.29357867,  0.27416367,  0.27669806,  0.31006797,  0.29547844,\n",
       "         0.29132183,  0.24164968,  0.27778345,  0.29423824,  0.3113258 ,\n",
       "         0.29999727,  0.22144429,  0.27484077,  0.28872787,  0.30244793,\n",
       "         0.29979904,  0.27529067,  0.30354404,  0.2932192 ,  0.31043324,\n",
       "         0.20980277,  0.30431756,  0.28764184,  0.2961437 ,  0.25165023,\n",
       "         0.28907642,  0.29542621,  0.29324136,  0.20886088,  0.31031848,\n",
       "         0.29355308,  0.28455068,  0.29909543,  0.30701388,  0.2747909 ,\n",
       "         0.26975153,  0.28789416,  0.26003438,  0.30264387,  0.27325516,\n",
       "         0.20693773,  0.28905338,  0.2396997 ,  0.29829229,  0.28274794,\n",
       "         0.30928039,  0.22044333,  0.29975461,  0.28906106,  0.30746284,\n",
       "         0.30043287,  0.3056243 ,  0.29414767,  0.29919217,  0.29236166,\n",
       "         0.29772975,  0.31452449,  0.29185523,  0.29133444,  0.29242772,\n",
       "         0.30736308,  0.30645021,  0.30102509,  0.30646663,  0.31091621,\n",
       "         0.31014828,  0.28421243,  0.27003351,  0.29305479,  0.30390545,\n",
       "         0.30585298,  0.30413364,  0.30923441,  0.29431977,  0.29149127,\n",
       "         0.30978209,  0.29490933,  0.30524698,  0.31108651,  0.29734335,\n",
       "         0.29951318,  0.29297617,  0.31217097,  0.30975278,  0.29594876,\n",
       "         0.26080777,  0.28621086,  0.30058824,  0.25428715,  0.30563829,\n",
       "         0.2880921 ,  0.23200964,  0.27950764,  0.29049652,  0.22172573,\n",
       "         0.28355425,  0.23858232,  0.29169927,  0.29713738,  0.28282858,\n",
       "         0.30808458,  0.26853581,  0.26988612,  0.26587261,  0.30910984,\n",
       "         0.29917778,  0.29086066,  0.30149472,  0.28955733,  0.30043638,\n",
       "         0.30696227,  0.30757913,  0.19276495,  0.21787583,  0.27336778,\n",
       "         0.28769828,  0.28775721,  0.288162  ,  0.30049676,  0.28009582,\n",
       "         0.29386356,  0.30505336,  0.27636736,  0.29809058,  0.30388199,\n",
       "         0.29285242,  0.29098848, -0.29415251, -0.28350224, -0.28634485,\n",
       "        -0.28303515, -0.28118231, -0.29613058, -0.29071795, -0.2754004 ,\n",
       "        -0.29095703, -0.2884933 , -0.29039041, -0.28896614, -0.29992073,\n",
       "        -0.29133667, -0.29146226]),\n",
       " 0,\n",
       " 0.5)"
      ]
     },
     "execution_count": 679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smartLoopTraditional(5, learnWeightsGammas, svmTest, x_trainOriginal, y_trainOriginal, x_testOriginal, y_testOriginal, epsilon, [0.01 for i in range(x_trainOriginal.shape[0])] ,[0 for i in range(x_trainOriginal.shape[1]+1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traditional: One Gamma - Merged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.07256, 0.07   , 0.07469, 0.07312, 0.06968, 0.06664, 0.07635,\n",
       "        0.07397, 0.06968, 0.06717, 0.07757, 0.07607, 0.07221, 0.07126,\n",
       "        0.06451, 0.06177, 0.07383, 0.07271, 0.07172, 0.06931, 0.08065,\n",
       "        0.07761, 0.0718 , 0.07   , 0.05818, 0.05424, 0.06897, 0.06686,\n",
       "        0.06308, 0.06005, 0.07671, 0.07523, 0.06548, 0.06568, 0.06846,\n",
       "        0.06551, 0.07165, 0.0698 , 0.06796, 0.06457, 0.06142, 0.05829,\n",
       "        0.05138, 0.04838, 0.00111]), 20.583399870000004, 0, 0.7875)"
      ]
     },
     "execution_count": 680,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smartLoopTraditional(5, learnWeights, svmTest, x_trainMerged, y_trainMerged, x_testMerged, y_testMerged, epsilon, 0.01 ,[0 for i in range(x_trainMerged.shape[1]+1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traditional: Multiple Gamma - Merged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.07256, 0.07   , 0.07469, 0.07312, 0.06968, 0.06664, 0.07635,\n",
       "        0.07397, 0.06968, 0.06717, 0.07757, 0.07607, 0.07221, 0.07126,\n",
       "        0.06451, 0.06177, 0.07383, 0.07271, 0.07172, 0.06931, 0.08065,\n",
       "        0.07761, 0.0718 , 0.07   , 0.05818, 0.05424, 0.06897, 0.06686,\n",
       "        0.06308, 0.06005, 0.07671, 0.07523, 0.06548, 0.06568, 0.06846,\n",
       "        0.06551, 0.07165, 0.0698 , 0.06796, 0.06457, 0.06142, 0.05829,\n",
       "        0.05138, 0.04838, 0.00111]),\n",
       " array([ 0.21259116,  0.21503722, -0.19344988,  0.19861926,  0.19870298,\n",
       "         0.18862452,  0.20527361,  0.20599274, -0.19858692, -0.19440856,\n",
       "         0.17713774,  0.21126631,  0.19980824,  0.21412846,  0.19604656,\n",
       "         0.19897681,  0.20973761,  0.19419203,  0.20981343,  0.21726762,\n",
       "         0.21087953,  0.21414115,  0.21546692, -0.19904517,  0.20639389,\n",
       "         0.18926811,  0.21776679,  0.15620352,  0.1890249 , -0.19871551,\n",
       "        -0.19848101,  0.14781727,  0.21692032,  0.14626525, -0.20191006,\n",
       "         0.20665697,  0.21723029,  0.20989433,  0.21328705,  0.21158999,\n",
       "         0.19964607,  0.1537945 ,  0.2144857 , -0.20176516,  0.18536511,\n",
       "         0.20447356,  0.20290812, -0.1907464 ,  0.16733551,  0.16981098,\n",
       "         0.2106913 , -0.2050622 , -0.19378822,  0.21719021,  0.20605333,\n",
       "         0.20519443,  0.1628907 ,  0.20191593, -0.20613839,  0.21495358,\n",
       "         0.21556058,  0.21390361,  0.2084487 ,  0.20218924,  0.20509698,\n",
       "         0.2098158 ,  0.21218461,  0.19302056, -0.19704525, -0.19744581,\n",
       "         0.18730635, -0.19818288, -0.20273513,  0.20842633, -0.20108801,\n",
       "         0.21010716,  0.2138156 ,  0.16997997,  0.2021316 ,  0.20661736,\n",
       "         0.20374354,  0.21263924,  0.20207342,  0.21681028, -0.20117275,\n",
       "         0.15033511,  0.20268589,  0.20990574,  0.21740623,  0.20158343,\n",
       "        -0.19887019,  0.21522653,  0.16691257,  0.21773812,  0.20276275,\n",
       "         0.20576761,  0.21405676,  0.20704908,  0.20169211,  0.18138909,\n",
       "        -0.20340646,  0.19432786,  0.21520957,  0.17067287,  0.20169142,\n",
       "         0.15434956,  0.21566494,  0.20581241,  0.21131441,  0.21534063,\n",
       "         0.20636109,  0.17866289, -0.19575458, -0.19423455,  0.20458784,\n",
       "         0.20710987,  0.21054051,  0.18958485,  0.21572751, -0.19431616,\n",
       "         0.19580395,  0.2038941 ,  0.21885949, -0.19349277,  0.2172319 ,\n",
       "         0.15563639,  0.21206913, -0.20294504, -0.200836  ,  0.19821861,\n",
       "         0.180786  ,  0.1712013 ,  0.21198786, -0.19607035,  0.20068318,\n",
       "         0.20490811,  0.21358903,  0.20545838, -0.20224835,  0.21406512,\n",
       "         0.20080523, -0.20078625,  0.20567082,  0.21788401,  0.21084741,\n",
       "         0.20401434, -0.20405158, -0.19577308, -0.20019037,  0.20461295,\n",
       "         0.17863614,  0.20694499, -0.20056012,  0.19811286,  0.21270011,\n",
       "         0.2024036 ,  0.18064444,  0.21714865,  0.20892308, -0.19452442,\n",
       "         0.17984319,  0.1931405 ,  0.19027903,  0.20163471, -0.19834664,\n",
       "         0.20406083,  0.20181543,  0.2074008 ,  0.17268177,  0.13632132,\n",
       "        -0.20111661, -0.19904389,  0.21110684,  0.19500141,  0.21645051,\n",
       "         0.18313948,  0.20372138,  0.20502077,  0.16903037,  0.20647654,\n",
       "         0.20650046, -0.19456167,  0.20239999,  0.2173059 ,  0.20713186,\n",
       "         0.2144905 ,  0.2045297 ]),\n",
       " 0,\n",
       " 0.7875)"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smartLoopTraditional(5, learnWeightsGammas, svmTest, x_trainMerged, y_trainMerged, x_testMerged, y_testMerged, epsilon, [0.01 for i in range(x_trainMerged.shape[0])] ,[0 for i in range(x_trainMerged.shape[1]+1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization: One Gamma - Original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.11195, 0.1094 , 0.11691, 0.11634, 0.10862, 0.1057 , 0.11807,\n",
       "        0.11634, 0.10759, 0.10544, 0.12048, 0.11909, 0.11356, 0.11289,\n",
       "        0.10281, 0.10031, 0.11391, 0.11308, 0.11292, 0.11089, 0.12553,\n",
       "        0.12235, 0.11401, 0.11235, 0.09676, 0.09233, 0.10936, 0.1067 ,\n",
       "        0.10314, 0.10053, 0.1203 , 0.11837, 0.10416, 0.1035 , 0.10856,\n",
       "        0.10537, 0.1117 , 0.1096 , 0.10897, 0.10513, 0.10224, 0.09786,\n",
       "        0.08723, 0.08303, 0.01157]), 47.422372149999994, 0, 0.5)"
      ]
     },
     "execution_count": 682,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smartLoopOptimization(5, learnWeightOptimization, svmTest, x_trainOriginal, y_trainOriginal, x_testOriginal, y_testOriginal, epsilon, 0.01, 0.01 ,[0 for i in range(x_trainOriginal.shape[1]+1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization: Multiple Gamma - Original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.11195, 0.1094 , 0.11691, 0.11634, 0.10862, 0.1057 , 0.11807,\n",
       "        0.11634, 0.10759, 0.10544, 0.12048, 0.11909, 0.11356, 0.11289,\n",
       "        0.10281, 0.10031, 0.11391, 0.11308, 0.11292, 0.11089, 0.12553,\n",
       "        0.12235, 0.11401, 0.11235, 0.09676, 0.09233, 0.10936, 0.1067 ,\n",
       "        0.10314, 0.10053, 0.1203 , 0.11837, 0.10416, 0.1035 , 0.10856,\n",
       "        0.10537, 0.1117 , 0.1096 , 0.10897, 0.10513, 0.10224, 0.09786,\n",
       "        0.08723, 0.08303, 0.01157]),\n",
       " array([ 0.33836585,  0.33082465,  0.33082977,  0.3313132 ,  0.32945278,\n",
       "         0.34166866,  0.32198823,  0.30660521,  0.28229355,  0.32315726,\n",
       "         0.30427474,  0.2921945 ,  0.32871972,  0.26672466,  0.27843482,\n",
       "         0.25548595,  0.33717674,  0.32134504,  0.29672798,  0.31434969,\n",
       "         0.31644758,  0.27975032,  0.28905383,  0.32246242,  0.31770066,\n",
       "         0.31581058,  0.31602463,  0.32674916,  0.33207156,  0.33581864,\n",
       "         0.34308278,  0.34090839,  0.26418023,  0.30817974,  0.33834932,\n",
       "         0.33458893,  0.33251415,  0.26855934,  0.24837027,  0.28279523,\n",
       "         0.25981346,  0.3404206 ,  0.31250942,  0.23925274,  0.31531426,\n",
       "         0.32231867,  0.30106367,  0.30355806,  0.34047797,  0.32438844,\n",
       "         0.32002183,  0.26509968,  0.30471345,  0.32293824,  0.3419258 ,\n",
       "         0.32936727,  0.24264429,  0.30139077,  0.31697787,  0.33206793,\n",
       "         0.32915904,  0.30244067,  0.33332404,  0.3217592 ,  0.34087324,\n",
       "         0.22992277,  0.33402756,  0.31574184,  0.3252037 ,  0.27592023,\n",
       "         0.31735642,  0.32434621,  0.32204136,  0.22909088,  0.34072848,\n",
       "         0.32223308,  0.31216068,  0.32834543,  0.33711388,  0.3013309 ,\n",
       "         0.29581153,  0.31614416,  0.28530438,  0.33228387,  0.29993516,\n",
       "         0.22674773,  0.31724338,  0.2626297 ,  0.32758229,  0.31049794,\n",
       "         0.33954039,  0.24141333,  0.32901461,  0.31722106,  0.33767284,\n",
       "         0.32976287,  0.3355743 ,  0.32288767,  0.32841217,  0.32089166,\n",
       "         0.32697975,  0.34544449,  0.32048523,  0.31962444,  0.32108772,\n",
       "         0.33748308,  0.33662021,  0.33059509,  0.33659663,  0.34152621,\n",
       "         0.34055828,  0.31192243,  0.29650351,  0.32173479,  0.33384545,\n",
       "         0.33593298,  0.33404364,  0.33957441,  0.32317977,  0.32017127,\n",
       "         0.34031209,  0.32393933,  0.33520698,  0.34169651,  0.32647335,\n",
       "         0.32900318,  0.32173617,  0.34280097,  0.34021278,  0.32501876,\n",
       "         0.28617777,  0.31415086,  0.33013824,  0.27907715,  0.33564829,\n",
       "         0.3162221 ,  0.25460964,  0.30683764,  0.31888652,  0.24281573,\n",
       "         0.31121425,  0.26186232,  0.32023927,  0.32618738,  0.31027858,\n",
       "         0.33837458,  0.29470581,  0.29642612,  0.29140261,  0.33944984,\n",
       "         0.32861778,  0.31946066,  0.33113472,  0.31807733,  0.32982638,\n",
       "         0.33709227,  0.33782913,  0.21106495,  0.23872583,  0.29995778,\n",
       "         0.31592828,  0.31600721,  0.316282  ,  0.32995676,  0.30730582,\n",
       "         0.32263356,  0.33501336,  0.30310736,  0.32744058,  0.33380199,\n",
       "         0.32159242,  0.31952848, -0.32469251, -0.31295224, -0.31600485,\n",
       "        -0.31238515, -0.31035231, -0.32682058, -0.32074795, -0.3041004 ,\n",
       "        -0.32120703, -0.3184533 , -0.32046041, -0.31889614, -0.33103073,\n",
       "        -0.32161667, -0.32161226]),\n",
       " 0,\n",
       " 0.5)"
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smartLoopOptimization(5, learnWeightOptimizationGammas, svmTest, x_trainOriginal, y_trainOriginal, x_testOriginal, y_testOriginal, epsilon, 0.01, [0.01 for i in range(x_trainOriginal.shape[0])] ,[0 for i in range(x_trainOriginal.shape[1]+1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization: One Gamma - Merged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.08256, 0.08   , 0.08469, 0.08312, 0.07968, 0.07664, 0.08635,\n",
       "        0.08397, 0.07968, 0.07717, 0.08757, 0.08607, 0.08221, 0.08126,\n",
       "        0.07451, 0.07177, 0.08383, 0.08271, 0.08172, 0.07931, 0.09065,\n",
       "        0.08761, 0.0818 , 0.08   , 0.06818, 0.06424, 0.07897, 0.07686,\n",
       "        0.07308, 0.07005, 0.08671, 0.08523, 0.07548, 0.07568, 0.07846,\n",
       "        0.07551, 0.08165, 0.0798 , 0.07796, 0.07457, 0.07142, 0.06829,\n",
       "        0.06138, 0.05838, 0.01111]), 23.591289870000004, 0, 0.7875)"
      ]
     },
     "execution_count": 686,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smartLoopOptimization(5, learnWeightOptimization, svmTest, x_trainMerged, y_trainMerged, x_testMerged, y_testMerged, epsilon, 0.01, 0.01 ,[0 for i in range(x_trainMerged.shape[1]+1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization: Multiple Gamma - Merged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.08256, 0.08   , 0.08469, 0.08312, 0.07968, 0.07664, 0.08635,\n",
       "        0.08397, 0.07968, 0.07717, 0.08757, 0.08607, 0.08221, 0.08126,\n",
       "        0.07451, 0.07177, 0.08383, 0.08271, 0.08172, 0.07931, 0.09065,\n",
       "        0.08761, 0.0818 , 0.08   , 0.06818, 0.06424, 0.07897, 0.07686,\n",
       "        0.07308, 0.07005, 0.08671, 0.08523, 0.07548, 0.07568, 0.07846,\n",
       "        0.07551, 0.08165, 0.0798 , 0.07796, 0.07457, 0.07142, 0.06829,\n",
       "        0.06138, 0.05838, 0.01111]),\n",
       " array([ 0.24253116,  0.24513722, -0.22279988,  0.22606926,  0.22607298,\n",
       "         0.21479452,  0.23403361,  0.23476274, -0.22865692, -0.22400856,\n",
       "         0.20140774,  0.24072631,  0.22741824,  0.24407846,  0.22337656,\n",
       "         0.22663681,  0.23922761,  0.22093203,  0.23928343,  0.24767762,\n",
       "         0.24045953,  0.24417115,  0.24568692, -0.22932517,  0.23510389,\n",
       "         0.21573811,  0.24836679,  0.17740352,  0.2155649 , -0.22887551,\n",
       "        -0.22860101,  0.16793727,  0.24730032,  0.16607525, -0.23243006,\n",
       "         0.23565697,  0.24775029,  0.23916433,  0.24325705,  0.24133999,\n",
       "         0.22745607,  0.1746445 ,  0.2446157 , -0.23234516,  0.21081511,\n",
       "         0.23301356,  0.23106812, -0.2198164 ,  0.19061551,  0.19326098,\n",
       "         0.2400213 , -0.2361722 , -0.22323822,  0.24758021,  0.23494333,\n",
       "         0.23393443,  0.1854907 ,  0.23004593, -0.23736839,  0.24508358,\n",
       "         0.24586058,  0.24379361,  0.2376987 ,  0.23048924,  0.23381698,\n",
       "         0.2390358 ,  0.24186461,  0.22017056, -0.22700525, -0.22734581,\n",
       "         0.21309635, -0.22833288, -0.23345513,  0.23762633, -0.23162801,\n",
       "         0.23953716,  0.2437756 ,  0.19307997,  0.2302516 ,  0.23548736,\n",
       "         0.23213354,  0.24241924,  0.23020342,  0.24727028, -0.23175275,\n",
       "         0.17098511,  0.23096589,  0.23906574,  0.24784623,  0.22960343,\n",
       "        -0.22912019,  0.24547653,  0.18987257,  0.24834812,  0.23128275,\n",
       "         0.23453761,  0.24410676,  0.23606908,  0.22994211,  0.20630909,\n",
       "        -0.23422646,  0.22118786,  0.24541957,  0.19447287,  0.22994142,\n",
       "         0.17511956,  0.24595494,  0.23470241,  0.24095441,  0.24546063,\n",
       "         0.23506109,  0.20345289, -0.22557458, -0.22382455,  0.23287784,\n",
       "         0.23601987,  0.24000051,  0.21564485,  0.24596751, -0.22381616,\n",
       "         0.22315395,  0.2324341 ,  0.24964949, -0.22268277,  0.2476419 ,\n",
       "         0.17660639,  0.24170913, -0.23368504, -0.231236  ,  0.22596861,\n",
       "         0.205816  ,  0.1947513 ,  0.24160786, -0.22582035,  0.22862318,\n",
       "         0.23367811,  0.24354903,  0.23425838, -0.23280835,  0.24407512,\n",
       "         0.22871523, -0.23117625,  0.23421082,  0.24848401,  0.24041741,\n",
       "         0.23271434, -0.23502158, -0.22543308, -0.23056037,  0.23307295,\n",
       "         0.20307614,  0.23606499, -0.23103012,  0.22532286,  0.24262011,\n",
       "         0.2306536 ,  0.20538444,  0.24755865,  0.23821308, -0.22409442,\n",
       "         0.20435319,  0.2196905 ,  0.21656903,  0.22986471, -0.22834664,\n",
       "         0.23271083,  0.22981543,  0.2364708 ,  0.19621177,  0.15462132,\n",
       "        -0.23160661, -0.22921389,  0.24063684,  0.22193141,  0.24679051,\n",
       "         0.20850948,  0.23232138,  0.23355077,  0.19196037,  0.23510654,\n",
       "         0.23553046, -0.22412167,  0.23044999,  0.2478559 ,  0.23605186,\n",
       "         0.2446605 ,  0.2331597 ]),\n",
       " 0,\n",
       " 0.7875)"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smartLoopOptimization(5, learnWeightOptimizationGammas, svmTest, x_trainMerged, y_trainMerged, x_testMerged, y_testMerged, epsilon, 0.01, [0.01 for i in range(x_trainMerged.shape[0])] ,[0 for i in range(x_trainMerged.shape[1]+1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM: Tuning Hyper-parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization Tuning:\n",
    "#### ----- > Lambda\n",
    "#### ----- > Epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traditional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original: One Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learningEpsilon1Original():\n",
    "    allparams = [ 0.001, 0.01, 0.1, 1, 10, 100, 150, 0.0000001,0.00000008, 0.0000000001, 0.01, 0.1, 0.001, 0.0001, 0.00000000001, 0.5, 0.9, 0.00000001]\n",
    "\n",
    "    runtimeNN_LR = []\n",
    "    maxValue = float('-inf')\n",
    "    indexFinal = None\n",
    "    for index,value in enumerate(allparams):   \n",
    "        \n",
    "        ##(finalW, finalG, loop, finalA)\n",
    "        \n",
    "        start = time.time()\n",
    "        wNew,gNew,loop,acc=smartLoopTraditional(5, learnWeights, svmTestSpecialCase, x_trainOriginal, y_trainOriginal, x_testOriginal, y_testOriginal, value, 0.01 ,[0 for i in range(x_trainOriginal.shape[1]+1)])\n",
    "        end = time.time()\n",
    "        runtimeNN_LR.append(end-start)\n",
    "        \n",
    "        accuracy = svmTestSpecialCase(x_testOriginal, wNew, y_testOriginal)\n",
    "        \n",
    "        if(accuracy>maxValue):\n",
    "            maxValue = accuracy\n",
    "            indexFinal = index\n",
    "            \n",
    "    return([allparams[indexFinal], maxValue, sum(runtimeNN_LR)/len(runtimeNN_LR)])            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.001, 0.5, 0.049323850207858615]"
      ]
     },
     "execution_count": 697,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learningEpsilon1Original()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merged: One Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learningEpsilon1Merged():\n",
    "    allparams = [ 0.001, 0.01, 0.1, 1, 10, 100, 150, 0.0000001,0.00000008, 0.0000000001, 0.01, 0.1, 0.001, 0.0001, 0.00000000001, 0.5, 0.9, 0.00000001]\n",
    "\n",
    "    runtimeNN_LR = []\n",
    "    maxValue = float('-inf')\n",
    "    indexFinal = None\n",
    "    for index,value in enumerate(allparams):   \n",
    "        \n",
    "        \n",
    "        start = time.time()\n",
    "        wNew,gNew,loop,acc=smartLoopTraditional(5, learnWeights, svmTestSpecialCase, x_trainMerged, y_trainMerged, x_testMerged, y_testMerged, value, 0.01 ,[0 for i in range(x_trainMerged.shape[1]+1)])\n",
    "        end = time.time()\n",
    "        runtimeNN_LR.append(end-start)\n",
    "        \n",
    "        accuracy = svmTestSpecialCase(x_testMerged, wNew, y_testMerged)\n",
    "        \n",
    "        if(accuracy>maxValue):\n",
    "            maxValue = accuracy\n",
    "            indexFinal = index\n",
    "            \n",
    "    return([allparams[indexFinal], maxValue, sum(runtimeNN_LR)/len(runtimeNN_LR)])            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.001, 0.7875, 0.04870308770073785]"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learningEpsilon1Merged()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original: Multiple Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learningEpsilon2Original():\n",
    "    allparams = [ 0.001, 0.01, 0.1, 1, 10, 100, 150, 0.0000001,0.00000008, 0.0000000001, 0.01, 0.1, 0.001, 0.0001, 0.00000000001, 0.5, 0.9, 0.00000001]\n",
    "\n",
    "    runtimeNN_LR = []\n",
    "    maxValue = float('-inf')\n",
    "    indexFinal = None\n",
    "    for index,value in enumerate(allparams):   \n",
    "        \n",
    "        \n",
    "        start = time.time()\n",
    "        wNew,gNew,loop,acc=smartLoopTraditional(5, learnWeightsGammas, svmTestSpecialCase, x_trainOriginal, y_trainOriginal, x_testOriginal, y_testOriginal, value, [0.01 for i in range(x_trainOriginal.shape[0])] ,[0 for i in range(x_trainOriginal.shape[1]+1)])\n",
    "        end = time.time()\n",
    "        runtimeNN_LR.append(end-start)\n",
    "        \n",
    "        accuracy = svmTestSpecialCase(x_testOriginal, wNew, y_testOriginal)\n",
    "        \n",
    "        if(accuracy>maxValue):\n",
    "            maxValue = accuracy\n",
    "            indexFinal = index\n",
    "            \n",
    "    return([allparams[indexFinal], maxValue, sum(runtimeNN_LR)/len(runtimeNN_LR)])            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.001, 0.5, 0.06765239768558079]"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learningEpsilon2Original()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merged: Multiple Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learningEpsilon2Merged():\n",
    "    allparams = [ 0.001, 0.01, 0.1, 1, 10, 100, 150, 0.0000001,0.00000008, 0.0000000001, 0.01, 0.1, 0.001, 0.0001, 0.00000000001, 0.5, 0.9, 0.00000001]\n",
    "\n",
    "    runtimeNN_LR = []\n",
    "    maxValue = float('-inf')\n",
    "    indexFinal = None\n",
    "    for index,value in enumerate(allparams):   \n",
    "        \n",
    "        \n",
    "        start = time.time()\n",
    "        wNew,gNew,loop,acc=smartLoopTraditional(5, learnWeightsGammas, svmTestSpecialCase, x_trainMerged, y_trainMerged, x_testMerged, y_testMerged, value, [0.01 for i in range(x_trainMerged.shape[0])] ,[0 for i in range(x_trainMerged.shape[1]+1)])\n",
    "        end = time.time()\n",
    "        runtimeNN_LR.append(end-start)\n",
    "        \n",
    "        accuracy = svmTestSpecialCase(x_testMerged, wNew, y_testMerged)\n",
    "        \n",
    "        if(accuracy>maxValue):\n",
    "            maxValue = accuracy\n",
    "            indexFinal = index\n",
    "            \n",
    "    return([allparams[indexFinal], maxValue, sum(runtimeNN_LR)/len(runtimeNN_LR)])            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.001, 0.7875, 0.069571057955424]"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learningEpsilon2Merged()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization: Epsilon and Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original: One Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learningOptimization1Original():\n",
    "    allepsilon = [ 0.001, 0.01, 0.1, 1, 10, 100, 150, 0.0000001,0.00000008, 0.0000000001, 0.01, 0.1, 0.001, 0.0001, 0.00000000001, 0.5, 0.9, 0.00000001]\n",
    "    alllambdas = [0.00001,0.0001,0.001,0.01,0.1,1,10,100,1000,10000]\n",
    "    \n",
    "    runtimeNN_LR = []\n",
    "    maxValue = float('-inf')\n",
    "    indexEpsilonFinal = None\n",
    "    indexLambdaFinal = None\n",
    "    for indexE,valueEpsilon in enumerate(allepsilon):   \n",
    "        for indexL,valueLambda in enumerate(alllambdas):\n",
    "            ##(finalW, finalG, loop, finalA)\n",
    "        \n",
    "            start = time.time()\n",
    "            wNew,gNew,loop,acc=smartLoopOptimization(5, learnWeightOptimization, svmTestSpecialCase, x_trainOriginal, y_trainOriginal, x_testOriginal, y_testOriginal, valueEpsilon, valueLambda, 0.01 ,[0 for i in range(x_trainOriginal.shape[1]+1)])\n",
    "            end = time.time()\n",
    "            runtimeNN_LR.append(end-start)\n",
    "\n",
    "            accuracy = svmTestSpecialCase(x_testOriginal, wNew, y_testOriginal)\n",
    "\n",
    "            if(accuracy>maxValue):\n",
    "                maxValue = accuracy\n",
    "                indexEpsilonFinal = indexE\n",
    "                indexLambdaFinal = indexL\n",
    "\n",
    "        \n",
    "    return([allepsilon[indexEpsilonFinal],alllambdas[indexLambdaFinal], maxValue, sum(runtimeNN_LR)/len(runtimeNN_LR)])            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.001, 1e-05, 0.5, 0.04758884244494968]"
      ]
     },
     "execution_count": 723,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learningOptimization1Original()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original: Multiple Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learningOptimization2Original():\n",
    "    allepsilon = [ 0.001, 0.01, 0.1, 1, 10, 100, 150, 0.0000001,0.00000008, 0.0000000001, 0.01, 0.1, 0.001, 0.0001, 0.00000000001, 0.5, 0.9, 0.00000001]\n",
    "    alllambdas = [0.00001,0.0001,0.001,0.01,0.1,1,10,100,1000,10000]\n",
    "    \n",
    "    runtimeNN_LR = []\n",
    "    maxValue = float('-inf')\n",
    "    indexEpsilonFinal = None\n",
    "    indexLambdaFinal = None\n",
    "    for indexE,valueEpsilon in enumerate(allepsilon):   \n",
    "        for indexL,valueLambda in enumerate(alllambdas):\n",
    "            ##(finalW, finalG, loop, finalA)\n",
    "        \n",
    "            start = time.time()\n",
    "            wNew,gNew,loop,acc=smartLoopOptimization(5, learnWeightOptimizationGammas, svmTestSpecialCase, x_trainOriginal, y_trainOriginal, x_testOriginal, y_testOriginal, valueEpsilon, valueLambda, [0.01 for i in range(x_trainMerged.shape[0])] ,[0 for i in range(x_trainOriginal.shape[1]+1)])\n",
    "            end = time.time()\n",
    "            runtimeNN_LR.append(end-start)\n",
    "\n",
    "            accuracy = svmTestSpecialCase(x_testOriginal, wNew, y_testOriginal)\n",
    "\n",
    "            if(accuracy>maxValue):\n",
    "                maxValue = accuracy\n",
    "                indexEpsilonFinal = indexE\n",
    "                indexLambdaFinal = indexL\n",
    "\n",
    "        \n",
    "    return([allepsilon[indexEpsilonFinal],alllambdas[indexLambdaFinal], maxValue, sum(runtimeNN_LR)/len(runtimeNN_LR)])            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.001, 1e-05, 0.5, 0.06625393364164564]"
      ]
     },
     "execution_count": 727,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learningOptimization2Original()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merged: One Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learningOptimization1Merged():\n",
    "    allepsilon = [ 0.001, 0.01, 0.1, 1, 10, 100, 150, 0.0000001,0.00000008, 0.0000000001, 0.01, 0.1, 0.001, 0.0001, 0.00000000001, 0.5, 0.9, 0.00000001]\n",
    "    alllambdas = [0.00001,0.0001,0.001,0.01,0.1,1,10,100,1000,10000]\n",
    "    \n",
    "    runtimeNN_LR = []\n",
    "    maxValue = float('-inf')\n",
    "    indexEpsilonFinal = None\n",
    "    indexLambdaFinal = None\n",
    "    for indexE,valueEpsilon in enumerate(allepsilon):   \n",
    "        for indexL,valueLambda in enumerate(alllambdas):\n",
    "            ##(finalW, finalG, loop, finalA)\n",
    "        \n",
    "            start = time.time()\n",
    "            wNew,gNew,loop,acc=smartLoopOptimization(5, learnWeightOptimization, svmTestSpecialCase, x_trainMerged, y_trainMerged, x_testMerged, y_testMerged, valueEpsilon, valueLambda, 0.01 ,[0 for i in range(x_trainMerged.shape[1]+1)])\n",
    "            end = time.time()\n",
    "            runtimeNN_LR.append(end-start)\n",
    "\n",
    "            accuracy = svmTestSpecialCase(x_testMerged, wNew, y_testMerged)\n",
    "\n",
    "            if(accuracy>maxValue):\n",
    "                maxValue = accuracy\n",
    "                indexEpsilonFinal = indexE\n",
    "                indexLambdaFinal = indexL\n",
    "\n",
    "        \n",
    "    return([allepsilon[indexEpsilonFinal],alllambdas[indexLambdaFinal], maxValue, sum(runtimeNN_LR)/len(runtimeNN_LR)])            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.001, 1e-05, 0.7875, 0.04745648569530911]"
      ]
     },
     "execution_count": 731,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learningOptimization1Merged()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merged: Multiple Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learningOptimization2Merged():\n",
    "    allepsilon = [ 0.001, 0.01, 0.1, 1, 10, 100, 150, 0.0000001,0.00000008, 0.0000000001, 0.01, 0.1, 0.001, 0.0001, 0.00000000001, 0.5, 0.9, 0.00000001]\n",
    "    alllambdas = [0.00001,0.0001,0.001,0.01,0.1,1,10,100,1000,10000]\n",
    "    \n",
    "    runtimeNN_LR = []\n",
    "    maxValue = float('-inf')\n",
    "    indexEpsilonFinal = None\n",
    "    indexLambdaFinal = None\n",
    "    for indexE,valueEpsilon in enumerate(allepsilon):   \n",
    "        for indexL,valueLambda in enumerate(alllambdas):\n",
    "            ##(finalW, finalG, loop, finalA)\n",
    "        \n",
    "            start = time.time()\n",
    "            wNew,gNew,loop,acc=smartLoopOptimization(5, learnWeightOptimizationGammas, svmTestSpecialCase, x_trainMerged, y_trainMerged, x_testMerged, y_testMerged, valueEpsilon, valueLambda, [0.01 for i in range(x_trainMerged.shape[0])] ,[0 for i in range(x_trainMerged.shape[1]+1)])\n",
    "            end = time.time()\n",
    "            runtimeNN_LR.append(end-start)\n",
    "\n",
    "            accuracy = svmTestSpecialCase(x_testMerged, wNew, y_testMerged)\n",
    "\n",
    "            if(accuracy>maxValue):\n",
    "                maxValue = accuracy\n",
    "                indexEpsilonFinal = indexE\n",
    "                indexLambdaFinal = indexL\n",
    "\n",
    "        \n",
    "    return([allepsilon[indexEpsilonFinal],alllambdas[indexLambdaFinal], maxValue, sum(runtimeNN_LR)/len(runtimeNN_LR)])            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.001, 1e-05, 0.7875, 0.07038614484998915]"
      ]
     },
     "execution_count": 729,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learningOptimization2Merged()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network: scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100, ), activation='relu', \n",
    "                    solver='adam', alpha=0.0001, batch_size='auto', \n",
    "                    learning_rate='constant', learning_rate_init=0.001, \n",
    "                    power_t=0.5, max_iter=200, shuffle=True, \n",
    "                    random_state=random_seed, tol=0.0001, verbose=False, \n",
    "                    warm_start=False, momentum=0.9, nesterovs_momentum=True, \n",
    "                    early_stopping=False, validation_fraction=0.1, \n",
    "                    beta_1=0.9, beta_2=0.999, epsilon=1e-08, \n",
    "                    n_iter_no_change=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning and runtime calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime of Learning - Neural Network by default [0.012937068939208984]\n"
     ]
    }
   ],
   "source": [
    "runtimeNN = []\n",
    "start = time.time()\n",
    "mlp.fit(x_trainOriginal,y_trainOriginal) \n",
    "end = time.time()\n",
    "runtimeNN.append(end-start)\n",
    "print(\"Runtime of Learning - Neural Network by default\", runtimeNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 50.0\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.17      0.26        40\n",
      "           1       0.50      0.82      0.62        40\n",
      "\n",
      "   micro avg       0.50      0.50      0.50        80\n",
      "   macro avg       0.50      0.50      0.44        80\n",
      "weighted avg       0.50      0.50      0.44        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_prediction = mlp.predict(x_testOriginal)\n",
    "\n",
    "print(\"The accuracy is\", metrics.accuracy_score(y_testOriginal,y_prediction)*100)\n",
    "print(\"Classification report:\")\n",
    "print(metrics.classification_report(y_testOriginal, y_prediction))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning and runtime calculation for Merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime of Learning (Merged) - Neural Network by default [0.3849678039550781]\n"
     ]
    }
   ],
   "source": [
    "runtimeNN = []\n",
    "start = time.time()\n",
    "mlp.fit(x_trainMerged,y_trainMerged) \n",
    "end = time.time()\n",
    "runtimeNN.append(end-start)\n",
    "print(\"Runtime of Learning (Merged) - Neural Network by default\", runtimeNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 78.75\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        17\n",
      "           1       0.79      1.00      0.88        63\n",
      "\n",
      "   micro avg       0.79      0.79      0.79        80\n",
      "   macro avg       0.39      0.50      0.44        80\n",
      "weighted avg       0.62      0.79      0.69        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_prediction = mlp.predict(x_testMerged)\n",
    "\n",
    "print(\"The accuracy is\", metrics.accuracy_score(y_testMerged,y_prediction)*100)\n",
    "print(\"Classification report:\")\n",
    "print(metrics.classification_report(y_testMerged, y_prediction))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparam tuning of Neural Network\n",
    "### To test: hidden layer, learning rate, epsilon\n",
    "#### explanation: https://towardsdatascience.com/what-are-hyperparameters-and-how-to-tune-the-hyperparameters-in-a-deep-neural-network-d0604917584a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Layer Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learningHiddenLayers():\n",
    "    hidden_layers = [(1,),(2,),(3,),(4,),(5,),(6,),(7,),(8,),(9,),(10,),(11,),(12,),(13,),(14,),(15,),(16,),(17,),(18,),(19,),(20,),(21,),(100,20),(40,30),(20,30),(25,15),(10,100),(10,10,10)]\n",
    "\n",
    "    runtimeNN_LR = []\n",
    "    maxValue = float('-inf')\n",
    "    indexFinal = None\n",
    "    for index,value in enumerate(hidden_layers):   \n",
    "        ## Neural Network with modification\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=value, activation='relu', \n",
    "                        solver='adam', alpha=0.0001, batch_size='auto', \n",
    "                        learning_rate='constant', learning_rate_init=0.001, \n",
    "                        power_t=0.5, max_iter=200, shuffle=True, \n",
    "                        random_state=random_seed, tol=0.0001, verbose=False, \n",
    "                        warm_start=False, momentum=0.9, nesterovs_momentum=True, \n",
    "                        early_stopping=False, validation_fraction=0.1, \n",
    "                        beta_1=0.9, beta_2=0.999, epsilon=1e-08, \n",
    "                        n_iter_no_change=10)\n",
    "        \n",
    "        start = time.time()\n",
    "        mlp.fit(x_trainOriginal,y_trainOriginal) \n",
    "        end = time.time()\n",
    "        runtimeNN_LR.append(end-start)\n",
    "        \n",
    "        y_prediction = mlp.predict(x_testOriginal)\n",
    "        \n",
    "        accuracy = metrics.accuracy_score(y_testOriginal,y_prediction)*100\n",
    "        \n",
    "        if(accuracy>maxValue):\n",
    "            maxValue = accuracy\n",
    "            indexFinal = index\n",
    "            \n",
    "    return([hidden_layers[indexFinal], maxValue, sum(runtimeNN_LR)/len(runtimeNN_LR)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4,), 55.00000000000001, 0.048610687255859375]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learningHiddenLayers() ## (4,)\n",
    "## Best value, accuracy, and average runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epsilon Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learningEpsilon(hidden_layer, learning_rate):\n",
    "    allparams = [0.00000008, 0.0000001, 0.0000000001, 0.01, 0.1, 0.001, 0.0001, 0.00000000001, 0.5, 0.9, 0.00000001]\n",
    "\n",
    "    runtimeNN_LR = []\n",
    "    maxValue = float('-inf')\n",
    "    indexFinal = None\n",
    "    for index,value in enumerate(allparams):   \n",
    "        ## Neural Network with modification\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=hidden_layer, activation='relu', \n",
    "                        solver='adam', alpha=0.0001, batch_size='auto', \n",
    "                        learning_rate='constant', learning_rate_init=learning_rate, \n",
    "                        power_t=0.5, max_iter=200, shuffle=True, \n",
    "                        random_state=random_seed, tol=0.0001, verbose=False, \n",
    "                        warm_start=False, momentum=0.9, nesterovs_momentum=True, \n",
    "                        early_stopping=False, validation_fraction=0.1, \n",
    "                        beta_1=0.9, beta_2=0.999, epsilon=value, \n",
    "                        n_iter_no_change=10)\n",
    "        \n",
    "        start = time.time()\n",
    "        mlp.fit(x_trainOriginal,y_trainOriginal) \n",
    "        end = time.time()\n",
    "        runtimeNN_LR.append(end-start)\n",
    "        \n",
    "        y_prediction = mlp.predict(x_testOriginal)\n",
    "        \n",
    "        accuracy = metrics.accuracy_score(y_testOriginal,y_prediction)*100\n",
    "        \n",
    "        if(accuracy>maxValue):\n",
    "            maxValue = accuracy\n",
    "            indexFinal = index\n",
    "            \n",
    "    return([allparams[indexFinal], maxValue, sum(runtimeNN_LR)/len(runtimeNN_LR)])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1, 51.24999999999999, 0.13590925390070135]\n",
      "[0.5, 62.5, 0.06954125924543901]\n",
      "[0.9, 55.00000000000001, 0.03218668157404119]\n",
      "[8e-08, 63.74999999999999, 0.01387201655994762]\n"
     ]
    }
   ],
   "source": [
    "print(learningEpsilon((100,),0.001)) ## default\n",
    "print(learningEpsilon((4,),0.001)) ## default\n",
    "print(learningEpsilon((100,),0.01))\n",
    "print(learningEpsilon((4,),0.01))\n",
    "## Best value, accuracy, and average runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Layer Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learningHiddenLayers():\n",
    "    hidden_layers = [(1,),(2,),(3,),(4,),(5,),(6,),(7,),(8,),(9,),(10,),(11,),(12,),(13,),(14,),(15,),(16,),(17,),(18,),(19,),(20,),(21,),(100,20),(40,30),(20,30),(25,15),(10,100),(10,10,10)]\n",
    "\n",
    "    runtimeNN_LR = []\n",
    "    maxValue = float('-inf')\n",
    "    indexFinal = None\n",
    "    for index,value in enumerate(hidden_layers):   \n",
    "        ## Neural Network with modification\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=value, activation='relu', \n",
    "                        solver='adam', alpha=0.0001, batch_size='auto', \n",
    "                        learning_rate='constant', learning_rate_init=0.001, \n",
    "                        power_t=0.5, max_iter=200, shuffle=True, \n",
    "                        random_state=random_seed, tol=0.0001, verbose=False, \n",
    "                        warm_start=False, momentum=0.9, nesterovs_momentum=True, \n",
    "                        early_stopping=False, validation_fraction=0.1, \n",
    "                        beta_1=0.9, beta_2=0.999, epsilon=1e-08, \n",
    "                        n_iter_no_change=10)\n",
    "        \n",
    "        start = time.time()\n",
    "        mlp.fit(x_trainMerged,y_trainMerged) \n",
    "        end = time.time()\n",
    "        runtimeNN_LR.append(end-start)\n",
    "        \n",
    "        y_prediction = mlp.predict(x_testMerged)\n",
    "        \n",
    "        accuracy = metrics.accuracy_score(y_testMerged,y_prediction)*100\n",
    "        \n",
    "        if(accuracy>maxValue):\n",
    "            maxValue = accuracy\n",
    "            indexFinal = index\n",
    "            \n",
    "    return([hidden_layers[indexFinal], maxValue, sum(runtimeNN_LR)/len(runtimeNN_LR)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2,), 78.75, 0.21933678344443994]"
      ]
     },
     "execution_count": 738,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learningHiddenLayers() ## (2,)\n",
    "## Best value, accuracy, and average runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epsilon Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learningEpsilon(hidden_layer, learning_rate):\n",
    "    allparams = [0.00000008, 0.0000001, 0.0000000001, 0.01, 0.1, 0.001, 0.0001, 0.00000000001, 0.5, 0.9, 0.00000001]\n",
    "\n",
    "    runtimeNN_LR = []\n",
    "    maxValue = float('-inf')\n",
    "    indexFinal = None\n",
    "    for index,value in enumerate(allparams):   \n",
    "        ## Neural Network with modification\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=hidden_layer, activation='relu', \n",
    "                        solver='adam', alpha=0.0001, batch_size='auto', \n",
    "                        learning_rate='constant', learning_rate_init=learning_rate, \n",
    "                        power_t=0.5, max_iter=200, shuffle=True, \n",
    "                        random_state=random_seed, tol=0.0001, verbose=False, \n",
    "                        warm_start=False, momentum=0.9, nesterovs_momentum=True, \n",
    "                        early_stopping=False, validation_fraction=0.1, \n",
    "                        beta_1=0.9, beta_2=0.999, epsilon=value, \n",
    "                        n_iter_no_change=10)\n",
    "        \n",
    "        start = time.time()\n",
    "        mlp.fit(x_trainMerged,y_trainMerged) \n",
    "        end = time.time()\n",
    "        runtimeNN_LR.append(end-start)\n",
    "        \n",
    "        y_prediction = mlp.predict(x_testMerged)\n",
    "        \n",
    "        accuracy = metrics.accuracy_score(y_testMerged,y_prediction)*100\n",
    "        \n",
    "        if(accuracy>maxValue):\n",
    "            maxValue = accuracy\n",
    "            indexFinal = index\n",
    "            \n",
    "    return([allparams[indexFinal], maxValue, sum(runtimeNN_LR)/len(runtimeNN_LR)])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5, 78.75, 0.7600971135226163]\n",
      "[8e-08, 78.75, 0.03803582624955611]\n",
      "[0.001, 80.0, 0.32138135216452857]\n",
      "[8e-08, 78.75, 0.033898028460415924]\n"
     ]
    }
   ],
   "source": [
    "print(learningEpsilon((100,),0.001)) ## default\n",
    "print(learningEpsilon((2,),0.001)) ## default\n",
    "print(learningEpsilon((100,),0.01))\n",
    "print(learningEpsilon((2,),0.01))\n",
    "## Best value, accuracy, and average runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuned Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hidden_layer = (4,)\n",
    "best_learning_rate = 0.01\n",
    "best_epsilon = 8e-08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=best_hidden_layer, activation='relu', \n",
    "                    solver='adam', alpha=0.0001, batch_size='auto', \n",
    "                    learning_rate='constant', learning_rate_init=best_learning_rate, \n",
    "                    power_t=0.5, max_iter=200, shuffle=True, \n",
    "                    random_state=random_seed, tol=0.0001, verbose=False, \n",
    "                    warm_start=False, momentum=0.9, nesterovs_momentum=True, \n",
    "                    early_stopping=False, validation_fraction=0.1, \n",
    "                    beta_1=0.9, beta_2=0.999, epsilon=best_epsilon, \n",
    "                    n_iter_no_change=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning and run time calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime of Learning - Neural Network Tuned [0.03486776351928711]\n"
     ]
    }
   ],
   "source": [
    "runtimeNN_tuned = []\n",
    "start = time.time()\n",
    "mlp.fit(x_trainOriginal,y_trainOriginal) \n",
    "end = time.time()\n",
    "runtimeNN_tuned.append(end-start)\n",
    "print(\"Runtime of Learning - Neural Network Tuned\", runtimeNN_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 63.74999999999999\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.97      0.73        40\n",
      "           1       0.92      0.30      0.45        40\n",
      "\n",
      "   micro avg       0.64      0.64      0.64        80\n",
      "   macro avg       0.75      0.64      0.59        80\n",
      "weighted avg       0.75      0.64      0.59        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_prediction = mlp.predict(x_testOriginal)\n",
    "\n",
    "print(\"The accuracy is\", metrics.accuracy_score(y_testOriginal,y_prediction)*100)\n",
    "print(\"Classification report:\")\n",
    "print(metrics.classification_report(y_testOriginal, y_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best hyper-parameters - Merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hidden_layer = (100,)\n",
    "best_learning_rate = 0.01\n",
    "best_epsilon = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=best_hidden_layer, activation='relu', \n",
    "                    solver='adam', alpha=0.0001, batch_size='auto', \n",
    "                    learning_rate='constant', learning_rate_init=best_learning_rate, \n",
    "                    power_t=0.5, max_iter=200, shuffle=True, \n",
    "                    random_state=random_seed, tol=0.0001, verbose=False, \n",
    "                    warm_start=False, momentum=0.9, nesterovs_momentum=True, \n",
    "                    early_stopping=False, validation_fraction=0.1, \n",
    "                    beta_1=0.9, beta_2=0.999, epsilon=best_epsilon, \n",
    "                    n_iter_no_change=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning and run time calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime of Learning - Neural Network Tuned [0.1495981216430664]\n"
     ]
    }
   ],
   "source": [
    "runtimeNN_tuned = []\n",
    "start = time.time()\n",
    "mlp.fit(x_trainMerged,y_trainMerged) \n",
    "end = time.time()\n",
    "runtimeNN_tuned.append(end-start)\n",
    "print(\"Runtime of Learning - Neural Network Tuned\", runtimeNN_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 80.0\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.06      0.11        17\n",
      "           1       0.80      1.00      0.89        63\n",
      "\n",
      "   micro avg       0.80      0.80      0.80        80\n",
      "   macro avg       0.90      0.53      0.50        80\n",
      "weighted avg       0.84      0.80      0.72        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_prediction = mlp.predict(x_testMerged)\n",
    "\n",
    "print(\"The accuracy is\", metrics.accuracy_score(y_testMerged,y_prediction)*100)\n",
    "print(\"Classification report:\")\n",
    "print(metrics.classification_report(y_testMerged, y_prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
